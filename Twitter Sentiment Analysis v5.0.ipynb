{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/lidia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/lidia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding='latin-1', names = ['label','id','date','noquery','handler','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>noquery</th>\n",
       "      <th>handler</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          id                          date   noquery          handler  \\\n",
       "0      0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                               tweet  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>noquery</th>\n",
       "      <th>handler</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>1467919452</td>\n",
       "      <td>Mon Apr 06 22:48:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@anistorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0</td>\n",
       "      <td>1467936498</td>\n",
       "      <td>Mon Apr 06 22:53:39 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@Anistorm Sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>0</td>\n",
       "      <td>1468219521</td>\n",
       "      <td>Tue Apr 07 00:22:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@jmielcarz send some of that warmness my way.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37902</th>\n",
       "      <td>0</td>\n",
       "      <td>1573108534</td>\n",
       "      <td>Mon Apr 20 23:45:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@Anistorm what's wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261409</th>\n",
       "      <td>0</td>\n",
       "      <td>1985909023</td>\n",
       "      <td>Sun May 31 18:00:15 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>likes that it is windy at work so he isn't as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606365</th>\n",
       "      <td>0</td>\n",
       "      <td>2222571467</td>\n",
       "      <td>Thu Jun 18 07:09:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@twckellycass the light at the video wall is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866347</th>\n",
       "      <td>4</td>\n",
       "      <td>1677596948</td>\n",
       "      <td>Sat May 02 02:57:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@TWCWeekends Happy 27th birthday, you guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288967</th>\n",
       "      <td>4</td>\n",
       "      <td>2002549306</td>\n",
       "      <td>Tue Jun 02 04:31:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@YourWxToday other than a few burnt out lights...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label          id                          date   noquery    handler  \\\n",
       "430          0  1467919452  Mon Apr 06 22:48:48 PDT 2009  NO_QUERY  jtmal0723   \n",
       "500          0  1467936498  Mon Apr 06 22:53:39 PDT 2009  NO_QUERY  jtmal0723   \n",
       "1733         0  1468219521  Tue Apr 07 00:22:07 PDT 2009  NO_QUERY  jtmal0723   \n",
       "37902        0  1573108534  Mon Apr 20 23:45:17 PDT 2009  NO_QUERY  jtmal0723   \n",
       "261409       0  1985909023  Sun May 31 18:00:15 PDT 2009  NO_QUERY  jtmal0723   \n",
       "606365       0  2222571467  Thu Jun 18 07:09:49 PDT 2009  NO_QUERY  jtmal0723   \n",
       "866347       4  1677596948  Sat May 02 02:57:06 PDT 2009  NO_QUERY  jtmal0723   \n",
       "1288967      4  2002549306  Tue Jun 02 04:31:54 PDT 2009  NO_QUERY  jtmal0723   \n",
       "\n",
       "                                                     tweet  \n",
       "430                                             @anistorm   \n",
       "500                                       @Anistorm Sorry   \n",
       "1733     @jmielcarz send some of that warmness my way.....  \n",
       "37902                             @Anistorm what's wrong?   \n",
       "261409   likes that it is windy at work so he isn't as ...  \n",
       "606365   @twckellycass the light at the video wall is r...  \n",
       "866347         @TWCWeekends Happy 27th birthday, you guys   \n",
       "1288967  @YourWxToday other than a few burnt out lights...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets['handler']=='jtmal0723']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      "label      1600000 non-null int64\n",
      "id         1600000 non-null int64\n",
      "date       1600000 non-null object\n",
      "noquery    1600000 non-null object\n",
      "handler    1600000 non-null object\n",
      "tweet      1600000 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.drop(['id', 'date','noquery','handler'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet\n",
       "0      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1      0  is upset that he can't update his Facebook by ...\n",
       "2      0  @Kenichan I dived many times for the ball. Man...\n",
       "3      0    my whole body feels itchy and like its on fire \n",
       "4      0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800000</td>\n",
       "      <td>790185</td>\n",
       "      <td>isPlayer Has Died! Sorry</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800000</td>\n",
       "      <td>793506</td>\n",
       "      <td>good morning</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet                                        \n",
       "        count  unique                        top freq\n",
       "label                                                \n",
       "0      800000  790185  isPlayer Has Died! Sorry   210\n",
       "4      800000  793506              good morning   118"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet  length\n",
       "0      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...     115\n",
       "1      0  is upset that he can't update his Facebook by ...     111\n",
       "2      0  @Kenichan I dived many times for the ball. Man...      89\n",
       "3      0    my whole body feels itchy and like its on fire       47\n",
       "4      0  @nationwideclass no, it's not behaving at all....     111"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['length'] = tweets['tweet'].apply(len)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets['label'] = tweets['label'].map({0: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.600000e+06\n",
       "mean     7.409011e+01\n",
       "std      3.644114e+01\n",
       "min      6.000000e+00\n",
       "25%      4.400000e+01\n",
       "50%      6.900000e+01\n",
       "75%      1.040000e+02\n",
       "max      3.740000e+02\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380539     @neospace à¹à¸£à¸·à¹à¸­à¸à¸à¸±à¹à¸à¸à¸£...\n",
       "1582941    5 days till new top gear  î?î?î?î?î?î?î?...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets['length'] == 359]['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x104e5bc88>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x106995f98>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets.hist(column='length', by='label', bins=50,figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat1 = r'@[A-Za-z0-9]+'\n",
    "# pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "# combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "# def tweet_cleaner(text):\n",
    "#     soup = BeautifulSoup(text, 'lxml')\n",
    "#     souped = soup.get_text()\n",
    "#     stripped = re.sub(combined_pat, '', souped)\n",
    "#     try:\n",
    "#         clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "#     except:\n",
    "#         clean = stripped\n",
    "#     letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "#     lower_case = letters_only.lower()\n",
    "#     # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "#     # I will tokenize and join together to remove unneccessary white spaces\n",
    "#     words = tok.tokenize(lower_case)\n",
    "#     return (\" \".join(words)).strip()\n",
    "\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0,400000,800000,1200000,1600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 10000 of 400000 has been processed\n",
      "Tweets 20000 of 400000 has been processed\n",
      "Tweets 30000 of 400000 has been processed\n",
      "Tweets 40000 of 400000 has been processed\n",
      "Tweets 50000 of 400000 has been processed\n",
      "Tweets 60000 of 400000 has been processed\n",
      "Tweets 70000 of 400000 has been processed\n",
      "Tweets 80000 of 400000 has been processed\n",
      "Tweets 90000 of 400000 has been processed\n",
      "Tweets 100000 of 400000 has been processed\n",
      "Tweets 110000 of 400000 has been processed\n",
      "Tweets 120000 of 400000 has been processed\n",
      "Tweets 130000 of 400000 has been processed\n",
      "Tweets 140000 of 400000 has been processed\n",
      "Tweets 150000 of 400000 has been processed\n",
      "Tweets 160000 of 400000 has been processed\n",
      "Tweets 170000 of 400000 has been processed\n",
      "Tweets 180000 of 400000 has been processed\n",
      "Tweets 190000 of 400000 has been processed\n",
      "Tweets 200000 of 400000 has been processed\n",
      "Tweets 210000 of 400000 has been processed\n",
      "Tweets 220000 of 400000 has been processed\n",
      "Tweets 230000 of 400000 has been processed\n",
      "Tweets 240000 of 400000 has been processed\n",
      "Tweets 250000 of 400000 has been processed\n",
      "Tweets 260000 of 400000 has been processed\n",
      "Tweets 270000 of 400000 has been processed\n",
      "Tweets 280000 of 400000 has been processed\n",
      "Tweets 290000 of 400000 has been processed\n",
      "Tweets 300000 of 400000 has been processed\n",
      "Tweets 310000 of 400000 has been processed\n",
      "Tweets 320000 of 400000 has been processed\n",
      "Tweets 330000 of 400000 has been processed\n",
      "Tweets 340000 of 400000 has been processed\n",
      "Tweets 350000 of 400000 has been processed\n",
      "Tweets 360000 of 400000 has been processed\n",
      "Tweets 370000 of 400000 has been processed\n",
      "Tweets 380000 of 400000 has been processed\n",
      "Tweets 390000 of 400000 has been processed\n",
      "Tweets 400000 of 400000 has been processed\n",
      "CPU times: user 1min 49s, sys: 6.03 s, total: 1min 55s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(nums[0],nums[1]):\n",
    "    if((i+1)%10000 == 0):\n",
    "        print(\"Tweets %d of %d has been processed\" % (i+1,nums[1]))                                                                   \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(tweets['tweet'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 410000 of 800000 has been processed\n",
      "Tweets 420000 of 800000 has been processed\n",
      "Tweets 430000 of 800000 has been processed\n",
      "Tweets 440000 of 800000 has been processed\n",
      "Tweets 450000 of 800000 has been processed\n",
      "Tweets 460000 of 800000 has been processed\n",
      "Tweets 470000 of 800000 has been processed\n",
      "Tweets 480000 of 800000 has been processed\n",
      "Tweets 490000 of 800000 has been processed\n",
      "Tweets 500000 of 800000 has been processed\n",
      "Tweets 510000 of 800000 has been processed\n",
      "Tweets 520000 of 800000 has been processed\n",
      "Tweets 530000 of 800000 has been processed\n",
      "Tweets 540000 of 800000 has been processed\n",
      "Tweets 550000 of 800000 has been processed\n",
      "Tweets 560000 of 800000 has been processed\n",
      "Tweets 570000 of 800000 has been processed\n",
      "Tweets 580000 of 800000 has been processed\n",
      "Tweets 590000 of 800000 has been processed\n",
      "Tweets 600000 of 800000 has been processed\n",
      "Tweets 610000 of 800000 has been processed\n",
      "Tweets 620000 of 800000 has been processed\n",
      "Tweets 630000 of 800000 has been processed\n",
      "Tweets 640000 of 800000 has been processed\n",
      "Tweets 650000 of 800000 has been processed\n",
      "Tweets 660000 of 800000 has been processed\n",
      "Tweets 670000 of 800000 has been processed\n",
      "Tweets 680000 of 800000 has been processed\n",
      "Tweets 690000 of 800000 has been processed\n",
      "Tweets 700000 of 800000 has been processed\n",
      "Tweets 710000 of 800000 has been processed\n",
      "Tweets 720000 of 800000 has been processed\n",
      "Tweets 730000 of 800000 has been processed\n",
      "Tweets 740000 of 800000 has been processed\n",
      "Tweets 750000 of 800000 has been processed\n",
      "Tweets 760000 of 800000 has been processed\n",
      "Tweets 770000 of 800000 has been processed\n",
      "Tweets 780000 of 800000 has been processed\n",
      "Tweets 790000 of 800000 has been processed\n",
      "Tweets 800000 of 800000 has been processed\n",
      "CPU times: user 1min 41s, sys: 5.23 s, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[1],nums[2]):\n",
    "    if((i+1)%10000 == 0):\n",
    "        print(\"Tweets %d of %d has been processed\" % (i+1,nums[2]))                                                                   \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(tweets['tweet'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 810000 of 1200000 has been processed\n",
      "Tweets 820000 of 1200000 has been processed\n",
      "Tweets 830000 of 1200000 has been processed\n",
      "Tweets 840000 of 1200000 has been processed\n",
      "Tweets 850000 of 1200000 has been processed\n",
      "Tweets 860000 of 1200000 has been processed\n",
      "Tweets 870000 of 1200000 has been processed\n",
      "Tweets 880000 of 1200000 has been processed\n",
      "Tweets 890000 of 1200000 has been processed\n",
      "Tweets 900000 of 1200000 has been processed\n",
      "Tweets 910000 of 1200000 has been processed\n",
      "Tweets 920000 of 1200000 has been processed\n",
      "Tweets 930000 of 1200000 has been processed\n",
      "Tweets 940000 of 1200000 has been processed\n",
      "Tweets 950000 of 1200000 has been processed\n",
      "Tweets 960000 of 1200000 has been processed\n",
      "Tweets 970000 of 1200000 has been processed\n",
      "Tweets 980000 of 1200000 has been processed\n",
      "Tweets 990000 of 1200000 has been processed\n",
      "Tweets 1000000 of 1200000 has been processed\n",
      "Tweets 1010000 of 1200000 has been processed\n",
      "Tweets 1020000 of 1200000 has been processed\n",
      "Tweets 1030000 of 1200000 has been processed\n",
      "Tweets 1040000 of 1200000 has been processed\n",
      "Tweets 1050000 of 1200000 has been processed\n",
      "Tweets 1060000 of 1200000 has been processed\n",
      "Tweets 1070000 of 1200000 has been processed\n",
      "Tweets 1080000 of 1200000 has been processed\n",
      "Tweets 1090000 of 1200000 has been processed\n",
      "Tweets 1100000 of 1200000 has been processed\n",
      "Tweets 1110000 of 1200000 has been processed\n",
      "Tweets 1120000 of 1200000 has been processed\n",
      "Tweets 1130000 of 1200000 has been processed\n",
      "Tweets 1140000 of 1200000 has been processed\n",
      "Tweets 1150000 of 1200000 has been processed\n",
      "Tweets 1160000 of 1200000 has been processed\n",
      "Tweets 1170000 of 1200000 has been processed\n",
      "Tweets 1180000 of 1200000 has been processed\n",
      "Tweets 1190000 of 1200000 has been processed\n",
      "Tweets 1200000 of 1200000 has been processed\n",
      "CPU times: user 1min 38s, sys: 4.85 s, total: 1min 42s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[2],nums[3]):\n",
    "    if((i+1)%10000 == 0):\n",
    "        print(\"Tweets %d of %d has been processed\" % (i+1,nums[3]))                                                                   \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(tweets['tweet'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tweet_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"@astynes Oh man, I think I'm becoming Switzerland. lol! I did my hair Bella-style this morning. Like in the cafetaria scene with Edward. \"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-63a08dd0bf62>\u001b[0m in \u001b[0;36mtweet_cleaner_updated\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtweet_cleaner_updated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0msouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mis_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0mis_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;31m# This is almost certainly a problem involving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (\"Cleaning and parsing the tweets...\\n\")\n",
    "for i in range(nums[3],nums[4]):\n",
    "    if((i+1)%10000 == 0):\n",
    "        print(\"Tweets %d of %d has been processed\" % (i+1,nums[4]))                                                                   \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(tweets['tweet'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = pd.DataFrame(clean_tweet_texts,columns=['clean tweet'])\n",
    "clean_tweets['label'] = tweets['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    800000\n",
       "1    408031\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets.to_csv('clean_tweet.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean tweet  label\n",
       "0  awww that bummer you shoulda got david carr of...      0\n",
       "1  is upset that he can not update his facebook b...      0\n",
       "2  dived many times for the ball managed to save ...      0\n",
       "3     my whole body feels itchy and like its on fire      0\n",
       "4  no it not behaving at all mad why am here beca...      0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'clean_tweet.csv'\n",
    "clean_tweets = pd.read_csv(csv,index_col=0)\n",
    "clean_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean tweet  label\n",
       "0  awww that bummer you shoulda got david carr of...      0\n",
       "1  is upset that he can not update his facebook b...      0\n",
       "2  dived many times for the ball managed to save ...      0\n",
       "3     my whole body feels itchy and like its on fire      0\n",
       "4  no it not behaving at all mad why am here beca...      0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1208031 entries, 0 to 1208030\n",
      "Data columns (total 2 columns):\n",
      "clean tweet    1205236 non-null object\n",
      "label          1208031 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 27.6+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clean tweet  label\n",
       "208         NaN      0\n",
       "249         NaN      0\n",
       "282         NaN      0\n",
       "398         NaN      0\n",
       "430         NaN      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets[clean_tweets.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2795"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(clean_tweets.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean tweet     True\n",
       "label          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like 3,959 entries have null entries for the text column. This is strange, because the original dataset had no null entries, and if there are any null entries in the cleaned dataset, it must have happened during the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0</td>\n",
       "      <td>1467863072</td>\n",
       "      <td>Mon Apr 06 22:33:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Artiel87</td>\n",
       "      <td>@mandayyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>1467874569</td>\n",
       "      <td>Mon Apr 06 22:36:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Artiel87</td>\n",
       "      <td>@mandayyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>1467881474</td>\n",
       "      <td>Mon Apr 06 22:38:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>__Susan__</td>\n",
       "      <td>@ITS_NEMESIS -------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>1467912842</td>\n",
       "      <td>Mon Apr 06 22:46:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KimberlyKane</td>\n",
       "      <td>@danadearmond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>1467919452</td>\n",
       "      <td>Mon Apr 06 22:48:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@anistorm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0           1                             2         3             4  \\\n",
       "208  0  1467863072  Mon Apr 06 22:33:25 PDT 2009  NO_QUERY      Artiel87   \n",
       "249  0  1467874569  Mon Apr 06 22:36:27 PDT 2009  NO_QUERY      Artiel87   \n",
       "282  0  1467881474  Mon Apr 06 22:38:20 PDT 2009  NO_QUERY     __Susan__   \n",
       "398  0  1467912842  Mon Apr 06 22:46:53 PDT 2009  NO_QUERY  KimberlyKane   \n",
       "430  0  1467919452  Mon Apr 06 22:48:48 PDT 2009  NO_QUERY     jtmal0723   \n",
       "\n",
       "                         5  \n",
       "208             @mandayyy   \n",
       "249           @mandayyy     \n",
       "282  @ITS_NEMESIS -------   \n",
       "398         @danadearmond   \n",
       "430             @anistorm   "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding = 'latin-1',header=None)\n",
    "df.iloc[clean_tweets[clean_tweets.isnull().any(axis=1)].index,:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at these entries in the original data, it seems like only text information they had was either twitter ID or it could have been URL address. Anyway, these are the info we decided to discard for the sentiment analysis, so we will drop these null rows, and update the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1205236 entries, 0 to 1205235\n",
      "Data columns (total 2 columns):\n",
      "clean tweet    1205236 non-null object\n",
      "label          1205236 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 18.4+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_tweets.dropna(inplace=True)\n",
    "clean_tweets.reset_index(drop=True,inplace=True)\n",
    "clean_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    798197\n",
       "1    407039\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud\n",
    "A word cloud represents word usage in a document by resizing individual words proportionally to its frequency and then presenting them in a random arrangement.Some of the concerns over word cloud is that, it supports only the crudest sorts of textual analysis, and it is often applied to situations where textual analysis is not appropriate, and it leaves viewers to figure out the context of the data by themselves without providing the narrative.\n",
    "\n",
    "But in the case of tweets, textual analysis is the most important analysis, and it provides a general idea of what kind of words are frequent in the corpus, in a sort of quick and dirty way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tweets = clean_tweets[clean_tweets['label'] == 0]\n",
    "neg_string = []\n",
    "for t in neg_tweets['clean tweet']:\n",
    "     neg_string.append(t)\n",
    "neg_string = pd.Series(neg_string).str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(width=1600, height=800,max_font_size=200).generate(neg_string)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = clean_tweets[clean_tweets['label'] == 1]\n",
    "pos_string = []\n",
    "for t in pos_tweets['clean tweet']:\n",
    "    pos_string.append(t)\n",
    "pos_string = pd.Series(pos_string).str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=1600, height=800,max_font_size=200,colormap= 'coolwarm').generate(pos_string)\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will sample the data points to have 100K points and will further divide to testing and training with 70% of the data in training and 30% of data in testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample100K = clean_tweets.sample(n=100000, random_state=101 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample100K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  Input : dataframe with a column names 'text' which contains raw tweets (one per row)\n",
    "#  Output: A list of lists of tokens corrsponding to the 'text' column\n",
    "#\n",
    "def tokenize_tweets2(tweets):\n",
    "    \"\"\"Given a df with tweets in 'text' col, this function return tokens as a list of lists\"\"\"\n",
    "\n",
    "    # apply tokenize to the 'text' coolumn in the tweets df\n",
    "    tweet_tokenizer = nltk.tokenize.TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "    tokens = tweets['tweet'].apply(tweet_tokenizer.tokenize)\n",
    "    \n",
    "    # filter\n",
    "    misc = ['rt', '’', '…', '—', 'u', '”', 'w', '“', '...', '️', 'http', 'https','..']\n",
    "    to_remove = nltk.corpus.stopwords.words('English') + list(string.punctuation) + misc\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    tokens = [[lemmatizer.lemmatize(token, pos='v') for token in tw if token not in to_remove] for tw in tokens]      \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = tokenize_tweets2(tweets_sample100K)\n",
    "print(len(all_tokens))\n",
    "all_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample100K['all_tokens']=all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample100K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample100K['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample100K[tweets_sample100K['length']==359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.violinplot(tweets_sample100K['length'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sample100K[tweets_sample100K['length']>140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow_transformer = CountVectorizer(analyzer = tokenize_tweets2).fit(tweets['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# counts = Counter([token for tokens in all_tokens for token in tokens])\n",
    "# print(len(counts))\n",
    "# counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_words = [k for k in counts.keys() if counts.get(k) > 50]\n",
    "# len(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingSet_10percent = trainingSet.sample(frac = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
